{
  "metadata": {
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    }
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": "# MGnify tutorial\nThis tutorial is a self-guided journey through some of the feature of the [MGnify](https://www.ebi.ac.uk/metagenomics) platform.\nWe will look at how to search for, browse, and download different kinds of datasets derived from metagenomic samples.\n\nThis tutorial is a JupyterLite notebook, which means there is a Python interpreter running in your web browser. This requires an up to date browser. The Python that runs here is a bit different to \"normal\" Python, so keep that in mind if you're trying to write your own code here.\n\nMost of the notebook is instructions and quiz questions, but there is also a bit of Python code if you're interested in how to access the data programatically. Knowing and using Python is not necessary to follow most of this tutorial.\n\n<div style=\"background: #d0debb; padding: 16px; border-radius: 4px; margin: 8px\">\nTo use this notebook, click the <b>Run</b> menu at the top, and then <b>Run all cells</b>.\n</div>\n\nYou can also run individual cells using the Play icon at the top, or type shift-enter in any cell to run it.\n\nFor help, contact `sandyr@ebi.ac.uk`\n\n---\n\n# Part 1: Exploring MGnify Studies\n## Task 1.1: Search for a MGnify study\n\nGo to the [MGnify website](https://www.ebi.ac.uk/metagenomics), and **use the \"Text Search\" feature to search for studies of marine sediment collected using an \"ROV\" (that's a _remote operated vehicle_) from the Environmental > Aquatic > Marine > Sediment biome.**\n\n_Hint: the use of an ROV is only mentioned in the study description, there is no specific metadata field for this._",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "%pip install -q ipywidgets",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "from utils.quiz import check_answer, _encode_answer, question",
      "metadata": {
        "trusted": true,
        "jupyter": {
          "source_hidden": true
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "question(\n    \"What is the MGnify Study accession (MGYS) of the first study that matches those parameters?\",\n    \"MGYSxxx\",\n    [b'bWd5czAwMDA1ODUx']\n)",
      "metadata": {
        "trusted": true,
        "jupyter": {
          "source_hidden": true
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "## Task 1.2: Find metadata for a study\n\nFollow the link on the study result above, to reach the detail page for that study on MGnify.\n\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "question(\n    \"Off the coast of which continent were most the study's samples collected?\",\n    \"\",\n    [b'c291dGggYW1lcmljYQ=='],\n    [\"Africa\", \"Antarctica\", \"Asia\", \"Europe\", \"North America\", \"Oceania\", \"South America\"]\n)",
      "metadata": {
        "trusted": true,
        "jupyter": {
          "source_hidden": true
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "Not all metadata are neatly organised in structured fields!\n\nVery often, the information you're interested in is only mentioned in the text descriptions of studies and samples uploaded to ENA, or even only in the \"Methods\" section of a publication.\n\n**Use the \"metadata from Europe PMC Annotations\" feature to discover published mentions of metadata about this study.**",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "question(\n    \"What is the deepest sampling *site* mentioned in the publication annotations?\",\n    \"\",\n    [b'OTMwMCAtIDEwMDEwIG0='],\n    [\"1000 m\", \"2560 m\", \"7720 - 8085 m\", \"9300 - 10010 m\"]\n)",
      "metadata": {
        "trusted": true,
        "jupyter": {
          "source_hidden": true
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "## Task 1.3: Finding common taxa in a study\n\nMGnify produces \"Analysis summaries\" for each Study. These summarise the taxonomic annotations over all of the sequencing runs (or assemblies) in the study. They are useful for getting a quick overview of the count of taxa present in each analysed sample.\n\nFor a study of amplicon sequences, sometimes there will be multiple analysis summaries originating from different databases (e.g. SSU, LSU, ITSone).\n\n**For the study [MGYS00005851](https://www.ebi.ac.uk/metagenomics/studies/MGYS00005851#analysis), find the most common Bacterial phyla using the SSU taxonomic summary.**",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "You could do this by downloading a TSV file and analysing it using something like Excel or R.\n\nOr, you can use the following Python code for a programmatic approach.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "import json\nfrom js import fetch\nimport pandas as pd\nfrom io import StringIO",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "# Download the TSV file programmatically:\nres = await fetch('https://www.ebi.ac.uk/metagenomics/api/v1/studies/MGYS00005851/pipelines/5.0/file/ERP116704_phylum_taxonomy_abundances_SSU_v5.0.tsv')\ntext = await res.text()\n# in a \"normal\" Python environment, this could be e.g. res = requests.get(\"https://...\"); text = res.text()\n# here we use js.fetch since we're running Python in the browser.\n\n# Read the TSV into a pandas dataframe\nitsone_taxonomies = pd.read_csv(StringIO(text), sep='\\t')\nitsone_taxonomies",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "# Sum the taxonomy counts across all runs in the study\nitsone_taxonomies['study_total'] = itsone_taxonomies.filter(like=\"ERR\").sum(axis=1)\n\n# Limit to phyla in the bacteria superkingdom\nitsone_bacteria = itsone_taxonomies[itsone_taxonomies.superkingdom == 'Bacteria']\nitsone_bacteria.set_index('phylum', inplace=True)\n\n# Show just the most prevalent phyla\nitsone_bacteria.sort_values(by=\"study_total\", ascending=False).head()",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "## Task 1.4: Think about the caveats...\n\n**Was what we just did (summing bacterial tax counts across all samples of the study) a good idea?**\n\nThings to consider: (Hint: Check the study page's \"Description\" and publication annotations from Schauberger _et al._)\n1. Were all of the sequencing runs targetting the 16s SSU region, so designed to barcode bacteria?\n2. Were the primers used likely to sequence the same taxa across all samples?\n\n<details>\n<summary>Tell me</summary>\nThe study description and publication mention that all samples were prepared with primers targetting SSUs, but that some were targetting 16s and some 18s. This means that it <b>is</b> fair to be only using the SSU taxonomic analysis summary across the study. However, it also mentions that some samples were prepared with primers specific to archaea, so there is likely a bias to different taxa in different samples. (In fact, a few different primers were used as can be seen by digging further into the metadata of the study, samples and publication.) This means our basic summation across all samples is likely not an unbiased measurement.\n</details>",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "---\n\n# Part 2: Exploring MGnify Analyses\n\n## Task 2.1: Search for a MGnify analysis\n\nLet's say we're particularly interested in Chloroflexi phylum (also known as Chloroflexota) – the third most prevalent Bacterial phylum in the study we were looking at in Part 1. \n\nGo to the [MGnify website](https://www.ebi.ac.uk/metagenomics/search/analyses), and **use the \"Text Search\" feature to search for _Sample analyses_, that contain Organisms in the Bacteria > Chloroflexi lineage, also collected from the Environmental > Aquatic > Marine > Sediment biome. Limit the search to samples analysed with MGnify's pipeline version 5.0 (the latest).**",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "question(\n    \"Look at the 'Experiment type' filter on the left of the search results: there are some <b>assembly</b> analyses.<br/>Why might we want to look into these next?\",\n    \"\",\n    [b'dG8gZGlzY292ZXIgZnVuY3Rpb25hbCBhbm5vdGF0aW9ucw=='],\n    [\"To browse complete genomes\", \"To get more taxonomic diversity\", \"To discover functional annotations\"]\n)",
      "metadata": {
        "trusted": true,
        "jupyter": {
          "source_hidden": true
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "## Task 2.2: Find annotations within an analysis\n**Limit your search to just those Assembly analyses.**\n\nThere are more filters we could use here, like location, or filtering to find analysis where a specific GO or InterPro functional annotation has been found on the assembled contigs.\n\nFor now, **scroll through the list to find MGYA00594115, and click it to open the analysis page.**",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "question(\n    \"According to the charts in the <b>Taxonomic analysis</b> section's SSU results, what fraction of the phylum composition is assigned to Chloroflexi?\",\n    \"x.yy %\",\n    [b'NC40OSAl', b'NC40OSU=', b'NC40OQ=='],\n)",
      "metadata": {
        "trusted": true,
        "jupyter": {
          "source_hidden": true
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "Now turn to the functional analysis information, in particular **the Pathways/Systems section.** Functional annotations of a metagenomic assembly are based on comparison of proteins coding sequences found in the assembly's contigs to databases of protein function such as KEGG orthologs. KEGG modules are pathways of KEGG orthologs, and a pathway's completeness is determined by the presence or absence of the minimum number of orthologs present to complete that pathway.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "question(\n    \"What is the first 'complete' KEGG Module for this assembly analysis?<br/>(Complete means all of the Kegg Orthologs in that module are present in the assembly.)\",\n    \"Mxxxxx\",\n    [b'bTAwMDAx', b'MDAwMDE='],\n)",
      "metadata": {
        "trusted": true,
        "jupyter": {
          "source_hidden": true
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "## Task 2.3: Think about what this means...\n\n**Does this mean that the Kegg Module you just found is necesarily a function performed by organisms within the taxa we originally searched for (Chloroflexi)?**\n\n_Consider that the functional annotations are on contigs from the entire assembly..._",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "---\n\n# Part 3: Metagenomic Assembled Genomes\n\nTo find functional annotations for a specific species, we can use metagenome assembly genomes (MAGs) – draft genomes made by taxonomically binning assembled contigs.\n[MGnify Genomes](https://www.ebi.ac.uk/metagenomics/browse/genomes) is MGnify's resource for MAGs, where MAGs derived from various biomes are organised into species-level clusters and annotated with a suite of functional annotation tools.\n\n## Task 3.1: Find Chloroflexi MAGs\n\n**Go to the [MGnify Genomes website](https://www.ebi.ac.uk/metagenomics/browse/genomes)**.\n\nGiven the biome we started this journey from, **which of the MGnify Genomes catalogues would you guess we're mostly like to find MAGs from the Chloroflexi phylum in?**\n\nLet's check. **Go to the \"All genomes\" list, and use the Filter to search for `Chloroflex`** (since this will catch lineages using either the `Chloroflexi` or `Chloroflexota` naming scheme).",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "question(\n    \"Which catalogue are most of the MAGs found in?\",\n    \"\",\n    [b'bWFyaW5l'],\n    [\"Marine\", \"Human Oral\", \"Zebrafish fecal\"]\n)",
      "metadata": {
        "trusted": true,
        "jupyter": {
          "source_hidden": true
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "## Task 3.2: Check functional annotations of a MAG\n\nFrom the list, **open the MAG for the species `Casp-Chloro-G4`**.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "question(\n    \"What is the most prevalent KEGG Module for this genome?\",\n    \"Mxxxxx\",\n    [b'bTAwMTc4', b'MDAxNzg='],\n)",
      "metadata": {
        "trusted": true,
        "jupyter": {
          "source_hidden": true
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "_Note that there are \"Download\" files available for both the assembly analysis we looked at before, and for this genome analysis, that include full listings of the Kegg annotations amongst others. You could download these files similarly to the study summary TSV file we analysed in Part 1, to compare these programmatically._",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "## Task 3.3: Cross-catalogue searching\nLooking at all the data you have available for this MAG, and exploring the other features available in the MGnify Genomes resource, can you work out how you might search for genomes similar to this one in other catalogues?\n\n<details>\n<summary>Tell me</summary>\nThe <a href=\"https://www.ebi.ac.uk/metagenomics/browse/genomes?browse-by=mag-search\">\"MAG search\" feature</a> uses <a href=\"https://sourmash.readthedocs.io/en/latest/\">Sourmash</a> to search genomes against genomes, based on sequence similarity. You could download the FASTA file of the MAG MGYG000297014, from its Downloads tab, and then upload this as the query genome to the MAG Search, selecting all catalogues as the target. At the time of writing, this search will only match the genome we downloaded from the marine catalogue.\n</details>",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "---\n\n# Further reading:\n\n### Latest MGnify publication\n\n> Richardson L, Allen B, Baldi G, et al. [MGnify: the microbiome sequence data analysis resource in 2023.](https://europepmc.org/article/PMC/PMC9825492) Nucleic Acids Research. 2023 Jan;51(D1):D753-D759. DOI: 10.1093/nar/gkac1080. PMID: 36477304; PMCID: PMC9825492.\n\n### MGnify Genomes publication\n> Gurbich TA, Almeida A, Beracochea M, et al. [MGnify Genomes: A Resource for Biome-specific Microbial Genome Catalogues.](https://europepmc.org/article/MED/36806692) Journal of Molecular Biology. 2023 Jul;435(14):168016. DOI: 10.1016/j.jmb.2023.168016. PMID: 36806692; PMCID: PMC10318097.\n\n\n### Documentation\n> [docs.mgnify.org](https://docs.mgnify.org)\n\n### MGnify training courses\n> [MGnify on EBI Training](https://www.ebi.ac.uk/training/search-results?query=mgnify)\n\n### Updates\n> [@MGnifyDB](https://twitter.com/mgnifyDB)",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}